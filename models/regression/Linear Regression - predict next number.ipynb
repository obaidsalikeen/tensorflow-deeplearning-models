{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression using TensorFlow.\n",
    "1. We will use raw TensorFlow to fit a line to our dataset. We will use random numbers as a dataset (contains 1 feature).\n",
    "2. Extend the example to perform linear regression on 1million examples with the help of batches (provide batches during train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Credits:\n",
    "These examples are inspired by following online Udemy course: \n",
    "- Complete Guide to TensorFlow for Deep Learning with Python by Jose Portilla\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Simple linear regression using a small dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.linspace(1, 10, 20) + np.random.uniform(high=1, low=-1, size=20)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = np.linspace(1,10,20) + np.random.uniform(high=2, low=-2, size=20)\n",
    "\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_label,'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the cost function\n",
    "- y = wx + b\n",
    "\n",
    "We already have `x_data` and `y_label` as our training data. Both these are Numpy arrays, however `w` and `b` are Tensorflow variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(initial_value=0.85)\n",
    "w = tf.Variable(initial_value=0.60)\n",
    "\n",
    "# Just give any value to error. error is our cost function\n",
    "error = 0\n",
    "\n",
    "for x,y in zip(x_data, y_label):\n",
    "    new_y = w*x + b\n",
    "    error += (y-new_y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the optimizer for GradientDecent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train = cost_function.minimize(loss=error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the Neural Network - train `w` and `b`\n",
    "- Optimize the cost function `error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trained_w = 0\n",
    "trained_b = 0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for x in range(epoch):\n",
    "        session.run(train)\n",
    "    \n",
    "    trained_w,trained_b = session.run([w,b])\n",
    "    \n",
    "    print(\" Trained values : trained_w {} trained_b {}\".format(trained_w, trained_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the decision boundary learned by the model (Line which fits the data best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trained = np.linspace(1,10, 20)\n",
    "y_trained = x_trained * trained_w + trained_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_label,'*')\n",
    "plt.plot(x_trained, y_trained)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Example of using batches to train with large dataset (1 million points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 1000000\n",
    "x_large = np.linspace(start=1, stop=10, num=dataset_size) + np.random.uniform(high=2, low=-2, size=dataset_size)\n",
    "y_large = np.linspace(start=1, stop=10, num=dataset_size) + np.random.uniform(high=2, low=-2, size=dataset_size)\n",
    "\n",
    "# Plot a random sample\n",
    "samples = 100\n",
    "random_sample_indexes = np.random.randint(0, high=dataset_size, size=samples)\n",
    "plt.plot(x_large[random_sample_indexes], y_large[random_sample_indexes], \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Variables\n",
    "batch_size = 8\n",
    "\n",
    "w = tf.Variable(0.86)\n",
    "b = tf.Variable(0.21)\n",
    "xPH = tf.placeholder(shape=[batch_size], dtype=tf.float32)\n",
    "yPH = tf.placeholder(shape=[batch_size], dtype=tf.float32)\n",
    "\n",
    "# Function:\n",
    "y_prediction =  w * xPH + b\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_sum(tf.square(yPH - y_prediction))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "cost_optimizer = optimizer.minimize(cost)\n",
    "\n",
    "# Train the model\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    for x in range(1000):\n",
    "        random_indexes = np.random.randint(0, high=dataset_size, size=batch_size)\n",
    "        feed_dict_map = {\n",
    "            xPH : x_large[random_indexes],\n",
    "            yPH : y_large[random_indexes]\n",
    "        }\n",
    "        session.run(cost_optimizer, feed_dict=feed_dict_map)\n",
    "        \n",
    "    w_trained, b_trained = session.run([w,b])\n",
    "\n",
    "    print(w_trained, b_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot samples using the trained `w` and `b` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_indexes = np.random.randint(0, high=dataset_size, size=samples)\n",
    "\n",
    "y_predicton = w_trained * x_large + b_trained\n",
    "\n",
    "plt.plot(x_large[random_sample_indexes], y_predicton[random_sample_indexes], 'r')\n",
    "plt.plot(x_large[random_sample_indexes], y_large[random_sample_indexes], '*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}